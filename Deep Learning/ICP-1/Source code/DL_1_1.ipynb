{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-1.1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTpb5bKBxi5vqEjTSXL3kl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harun2703/Python/blob/master/Deep%20Learning/ICP-1/Source%20code/DL_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RioHkM9vqDiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8c1e783d-70a3-4d0a-ca85-584552fc808c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Python Deep learning/icp-7/diabetes.csv\", header=None).values\n",
        "# print(dataset)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(dataset[:,0:8],  dataset[:,8],test_size=0.25, random_state=87)\n",
        "my_first_nn= Sequential() # create model\n",
        "\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(30))# hidden layer\n",
        "my_first_nn.add(Dense(40))# hidden layer\n",
        "\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted= my_first_nn.fit(X_train, Y_train, epochs=100, verbose=0,initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test, verbose=0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 20)                180       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 40)                1240      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 2,091\n",
            "Trainable params: 2,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "[0.7443240682284037, 0.6145833134651184]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMNjoEz2s6LX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fcb1206-7cc6-44b5-c9cc-f87d69a26684"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Python Deep learning/icp-7/Breas Cancer.csv\")\n",
        "\n",
        "x=dataset.iloc[:, [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]].values\n",
        "y=dataset.iloc[:,1].values\n",
        "lencoder = LabelEncoder()\n",
        "y= lencoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y,\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(30, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "426/426 [==============================] - 0s 256us/step - loss: 29.2033 - acc: 0.3615\n",
            "Epoch 2/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 9.9728 - acc: 0.4977\n",
            "Epoch 3/100\n",
            "426/426 [==============================] - 0s 62us/step - loss: 4.3964 - acc: 0.5329\n",
            "Epoch 4/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 1.7078 - acc: 0.7653\n",
            "Epoch 5/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.8860 - acc: 0.8357\n",
            "Epoch 6/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.6743 - acc: 0.8662\n",
            "Epoch 7/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.6333 - acc: 0.8662\n",
            "Epoch 8/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.5859 - acc: 0.8756\n",
            "Epoch 9/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.5637 - acc: 0.8920\n",
            "Epoch 10/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.5820 - acc: 0.8920\n",
            "Epoch 11/100\n",
            "426/426 [==============================] - 0s 70us/step - loss: 0.5860 - acc: 0.8803\n",
            "Epoch 12/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.4905 - acc: 0.9108\n",
            "Epoch 13/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.5142 - acc: 0.8873\n",
            "Epoch 14/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.5806 - acc: 0.8944\n",
            "Epoch 15/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.5425 - acc: 0.9085\n",
            "Epoch 16/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.4772 - acc: 0.8897\n",
            "Epoch 17/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.4373 - acc: 0.9038\n",
            "Epoch 18/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.4308 - acc: 0.9178\n",
            "Epoch 19/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.4646 - acc: 0.8967\n",
            "Epoch 20/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.4106 - acc: 0.9085\n",
            "Epoch 21/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.3857 - acc: 0.9131\n",
            "Epoch 22/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.3594 - acc: 0.9249\n",
            "Epoch 23/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.3659 - acc: 0.9131\n",
            "Epoch 24/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.3490 - acc: 0.9225\n",
            "Epoch 25/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.3326 - acc: 0.9178\n",
            "Epoch 26/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.3238 - acc: 0.9202\n",
            "Epoch 27/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.4250 - acc: 0.9014\n",
            "Epoch 28/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.3697 - acc: 0.9249\n",
            "Epoch 29/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.2913 - acc: 0.9272\n",
            "Epoch 30/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.3096 - acc: 0.9225\n",
            "Epoch 31/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.3223 - acc: 0.9178\n",
            "Epoch 32/100\n",
            "426/426 [==============================] - 0s 61us/step - loss: 0.2593 - acc: 0.9249\n",
            "Epoch 33/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.2727 - acc: 0.9272\n",
            "Epoch 34/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.2837 - acc: 0.9108\n",
            "Epoch 35/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.2736 - acc: 0.9178\n",
            "Epoch 36/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.2392 - acc: 0.9296\n",
            "Epoch 37/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.2357 - acc: 0.9249\n",
            "Epoch 38/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.2215 - acc: 0.9296\n",
            "Epoch 39/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.2339 - acc: 0.9319\n",
            "Epoch 40/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.3012 - acc: 0.9178\n",
            "Epoch 41/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.2054 - acc: 0.9296\n",
            "Epoch 42/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.2103 - acc: 0.9272\n",
            "Epoch 43/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.2028 - acc: 0.9413\n",
            "Epoch 44/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.1927 - acc: 0.9343\n",
            "Epoch 45/100\n",
            "426/426 [==============================] - 0s 63us/step - loss: 0.1783 - acc: 0.9390\n",
            "Epoch 46/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.1929 - acc: 0.9296\n",
            "Epoch 47/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1584 - acc: 0.9437\n",
            "Epoch 48/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.2454 - acc: 0.9202\n",
            "Epoch 49/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.2406 - acc: 0.9225\n",
            "Epoch 50/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.1756 - acc: 0.9296\n",
            "Epoch 51/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.1882 - acc: 0.9390\n",
            "Epoch 52/100\n",
            "426/426 [==============================] - 0s 43us/step - loss: 0.1711 - acc: 0.9390\n",
            "Epoch 53/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.1851 - acc: 0.9413\n",
            "Epoch 54/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.1513 - acc: 0.9343\n",
            "Epoch 55/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1791 - acc: 0.9413\n",
            "Epoch 56/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.1802 - acc: 0.9413\n",
            "Epoch 57/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.2298 - acc: 0.9319\n",
            "Epoch 58/100\n",
            "426/426 [==============================] - 0s 59us/step - loss: 0.1758 - acc: 0.9390\n",
            "Epoch 59/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.1462 - acc: 0.9460\n",
            "Epoch 60/100\n",
            "426/426 [==============================] - 0s 68us/step - loss: 0.1637 - acc: 0.9390\n",
            "Epoch 61/100\n",
            "426/426 [==============================] - 0s 75us/step - loss: 0.1693 - acc: 0.9390\n",
            "Epoch 62/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1599 - acc: 0.9390\n",
            "Epoch 63/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.1465 - acc: 0.9390\n",
            "Epoch 64/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1881 - acc: 0.9413\n",
            "Epoch 65/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.2103 - acc: 0.9343\n",
            "Epoch 66/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.1653 - acc: 0.9366\n",
            "Epoch 67/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.1370 - acc: 0.9437\n",
            "Epoch 68/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.1335 - acc: 0.9531\n",
            "Epoch 69/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.1444 - acc: 0.9437\n",
            "Epoch 70/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.1581 - acc: 0.9390\n",
            "Epoch 71/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.1468 - acc: 0.9366\n",
            "Epoch 72/100\n",
            "426/426 [==============================] - 0s 63us/step - loss: 0.1220 - acc: 0.9507\n",
            "Epoch 73/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.1971 - acc: 0.9272\n",
            "Epoch 74/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.3141 - acc: 0.9178\n",
            "Epoch 75/100\n",
            "426/426 [==============================] - 0s 64us/step - loss: 0.2076 - acc: 0.9108\n",
            "Epoch 76/100\n",
            "426/426 [==============================] - 0s 65us/step - loss: 0.2008 - acc: 0.9343\n",
            "Epoch 77/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.1582 - acc: 0.9319\n",
            "Epoch 78/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.1401 - acc: 0.9366\n",
            "Epoch 79/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.1599 - acc: 0.9460\n",
            "Epoch 80/100\n",
            "426/426 [==============================] - 0s 60us/step - loss: 0.1690 - acc: 0.9366\n",
            "Epoch 81/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.1398 - acc: 0.9366\n",
            "Epoch 82/100\n",
            "426/426 [==============================] - 0s 60us/step - loss: 0.1310 - acc: 0.9296\n",
            "Epoch 83/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.1191 - acc: 0.9484\n",
            "Epoch 84/100\n",
            "426/426 [==============================] - 0s 61us/step - loss: 0.1400 - acc: 0.9484\n",
            "Epoch 85/100\n",
            "426/426 [==============================] - 0s 78us/step - loss: 0.2043 - acc: 0.9178\n",
            "Epoch 86/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1281 - acc: 0.9437\n",
            "Epoch 87/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.1290 - acc: 0.9437\n",
            "Epoch 88/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.1275 - acc: 0.9413\n",
            "Epoch 89/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.1259 - acc: 0.9413\n",
            "Epoch 90/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.1379 - acc: 0.9554\n",
            "Epoch 91/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.1647 - acc: 0.9225\n",
            "Epoch 92/100\n",
            "426/426 [==============================] - 0s 63us/step - loss: 0.1263 - acc: 0.9484\n",
            "Epoch 93/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.1134 - acc: 0.9413\n",
            "Epoch 94/100\n",
            "426/426 [==============================] - 0s 64us/step - loss: 0.1248 - acc: 0.9507\n",
            "Epoch 95/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1217 - acc: 0.9390\n",
            "Epoch 96/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.1401 - acc: 0.9531\n",
            "Epoch 97/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.1300 - acc: 0.9437\n",
            "Epoch 98/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.1582 - acc: 0.9413\n",
            "Epoch 99/100\n",
            "426/426 [==============================] - 0s 68us/step - loss: 0.1185 - acc: 0.9554\n",
            "Epoch 100/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.1492 - acc: 0.9413\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 961\n",
            "Trainable params: 961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "143/143 [==============================] - 0s 181us/step\n",
            "[0.32976678055483144, 0.9090909361839294]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1xEGVGM7V4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cc69492-efb8-4408-e308-a0f5f5cd49aa"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Python Deep learning/icp-7/Breas Cancer.csv\")\n",
        "\n",
        "x=dataset.iloc[:, [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]].values\n",
        "y=dataset.iloc[:,1].values\n",
        "lencoder = LabelEncoder()\n",
        "y= lencoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y,\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc =StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(30, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "426/426 [==============================] - 0s 251us/step - loss: 0.6711 - acc: 0.6808\n",
            "Epoch 2/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.4440 - acc: 0.8005\n",
            "Epoch 3/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.3025 - acc: 0.9202\n",
            "Epoch 4/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.2235 - acc: 0.9554\n",
            "Epoch 5/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.1819 - acc: 0.9648\n",
            "Epoch 6/100\n",
            "426/426 [==============================] - 0s 61us/step - loss: 0.1571 - acc: 0.9671\n",
            "Epoch 7/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.1401 - acc: 0.9695\n",
            "Epoch 8/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.1272 - acc: 0.9718\n",
            "Epoch 9/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.1169 - acc: 0.9718\n",
            "Epoch 10/100\n",
            "426/426 [==============================] - 0s 63us/step - loss: 0.1086 - acc: 0.9742\n",
            "Epoch 11/100\n",
            "426/426 [==============================] - 0s 64us/step - loss: 0.1016 - acc: 0.9765\n",
            "Epoch 12/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0957 - acc: 0.9765\n",
            "Epoch 13/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.0905 - acc: 0.9789\n",
            "Epoch 14/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.0859 - acc: 0.9812\n",
            "Epoch 15/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0819 - acc: 0.9812\n",
            "Epoch 16/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.0784 - acc: 0.9812\n",
            "Epoch 17/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.0754 - acc: 0.9812\n",
            "Epoch 18/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.0723 - acc: 0.9812\n",
            "Epoch 19/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0695 - acc: 0.9812\n",
            "Epoch 20/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.0673 - acc: 0.9812\n",
            "Epoch 21/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.0650 - acc: 0.9836\n",
            "Epoch 22/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.0627 - acc: 0.9836\n",
            "Epoch 23/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.0609 - acc: 0.9836\n",
            "Epoch 24/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0590 - acc: 0.9836\n",
            "Epoch 25/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0574 - acc: 0.9836\n",
            "Epoch 26/100\n",
            "426/426 [==============================] - 0s 64us/step - loss: 0.0558 - acc: 0.9836\n",
            "Epoch 27/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0542 - acc: 0.9836\n",
            "Epoch 28/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.0529 - acc: 0.9836\n",
            "Epoch 29/100\n",
            "426/426 [==============================] - 0s 61us/step - loss: 0.0515 - acc: 0.9836\n",
            "Epoch 30/100\n",
            "426/426 [==============================] - 0s 97us/step - loss: 0.0502 - acc: 0.9836\n",
            "Epoch 31/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0490 - acc: 0.9836\n",
            "Epoch 32/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0478 - acc: 0.9859\n",
            "Epoch 33/100\n",
            "426/426 [==============================] - 0s 77us/step - loss: 0.0470 - acc: 0.9883\n",
            "Epoch 34/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0456 - acc: 0.9883\n",
            "Epoch 35/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0446 - acc: 0.9906\n",
            "Epoch 36/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.0438 - acc: 0.9906\n",
            "Epoch 37/100\n",
            "426/426 [==============================] - 0s 67us/step - loss: 0.0428 - acc: 0.9906\n",
            "Epoch 38/100\n",
            "426/426 [==============================] - 0s 59us/step - loss: 0.0420 - acc: 0.9930\n",
            "Epoch 39/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0410 - acc: 0.9930\n",
            "Epoch 40/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.0402 - acc: 0.9930\n",
            "Epoch 41/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0395 - acc: 0.9930\n",
            "Epoch 42/100\n",
            "426/426 [==============================] - 0s 60us/step - loss: 0.0387 - acc: 0.9930\n",
            "Epoch 43/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0381 - acc: 0.9930\n",
            "Epoch 44/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0374 - acc: 0.9930\n",
            "Epoch 45/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0368 - acc: 0.9930\n",
            "Epoch 46/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.0363 - acc: 0.9930\n",
            "Epoch 47/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.0355 - acc: 0.9930\n",
            "Epoch 48/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0350 - acc: 0.9930\n",
            "Epoch 49/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.0344 - acc: 0.9930\n",
            "Epoch 50/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.0339 - acc: 0.9930\n",
            "Epoch 51/100\n",
            "426/426 [==============================] - 0s 47us/step - loss: 0.0332 - acc: 0.9930\n",
            "Epoch 52/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0326 - acc: 0.9930\n",
            "Epoch 53/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.0322 - acc: 0.9930\n",
            "Epoch 54/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.0318 - acc: 0.9930\n",
            "Epoch 55/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.0312 - acc: 0.9930\n",
            "Epoch 56/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.0307 - acc: 0.9930\n",
            "Epoch 57/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.0304 - acc: 0.9930\n",
            "Epoch 58/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0298 - acc: 0.9930\n",
            "Epoch 59/100\n",
            "426/426 [==============================] - 0s 46us/step - loss: 0.0295 - acc: 0.9930\n",
            "Epoch 60/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0290 - acc: 0.9930\n",
            "Epoch 61/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.0286 - acc: 0.9930\n",
            "Epoch 62/100\n",
            "426/426 [==============================] - 0s 50us/step - loss: 0.0281 - acc: 0.9930\n",
            "Epoch 63/100\n",
            "426/426 [==============================] - 0s 48us/step - loss: 0.0281 - acc: 0.9930\n",
            "Epoch 64/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.0278 - acc: 0.9930\n",
            "Epoch 65/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.0273 - acc: 0.9930\n",
            "Epoch 66/100\n",
            "426/426 [==============================] - 0s 59us/step - loss: 0.0266 - acc: 0.9930\n",
            "Epoch 67/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0265 - acc: 0.9930\n",
            "Epoch 68/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0260 - acc: 0.9930\n",
            "Epoch 69/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.0257 - acc: 0.9930\n",
            "Epoch 70/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.0253 - acc: 0.9930\n",
            "Epoch 71/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.0249 - acc: 0.9930\n",
            "Epoch 72/100\n",
            "426/426 [==============================] - 0s 43us/step - loss: 0.0247 - acc: 0.9930\n",
            "Epoch 73/100\n",
            "426/426 [==============================] - 0s 43us/step - loss: 0.0244 - acc: 0.9930\n",
            "Epoch 74/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.0240 - acc: 0.9930\n",
            "Epoch 75/100\n",
            "426/426 [==============================] - 0s 43us/step - loss: 0.0237 - acc: 0.9930\n",
            "Epoch 76/100\n",
            "426/426 [==============================] - 0s 59us/step - loss: 0.0237 - acc: 0.9930\n",
            "Epoch 77/100\n",
            "426/426 [==============================] - 0s 54us/step - loss: 0.0240 - acc: 0.9930\n",
            "Epoch 78/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.0231 - acc: 0.9930\n",
            "Epoch 79/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0226 - acc: 0.9930\n",
            "Epoch 80/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0227 - acc: 0.9930\n",
            "Epoch 81/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0220 - acc: 0.9930\n",
            "Epoch 82/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.0218 - acc: 0.9930\n",
            "Epoch 83/100\n",
            "426/426 [==============================] - 0s 73us/step - loss: 0.0215 - acc: 0.9930\n",
            "Epoch 84/100\n",
            "426/426 [==============================] - 0s 59us/step - loss: 0.0214 - acc: 0.9930\n",
            "Epoch 85/100\n",
            "426/426 [==============================] - 0s 58us/step - loss: 0.0212 - acc: 0.9930\n",
            "Epoch 86/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0207 - acc: 0.9930\n",
            "Epoch 87/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0205 - acc: 0.9930\n",
            "Epoch 88/100\n",
            "426/426 [==============================] - 0s 56us/step - loss: 0.0204 - acc: 0.9930\n",
            "Epoch 89/100\n",
            "426/426 [==============================] - 0s 44us/step - loss: 0.0201 - acc: 0.9930\n",
            "Epoch 90/100\n",
            "426/426 [==============================] - 0s 43us/step - loss: 0.0199 - acc: 0.9930\n",
            "Epoch 91/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0198 - acc: 0.9930\n",
            "Epoch 92/100\n",
            "426/426 [==============================] - 0s 53us/step - loss: 0.0198 - acc: 0.9930\n",
            "Epoch 93/100\n",
            "426/426 [==============================] - 0s 49us/step - loss: 0.0194 - acc: 0.9930\n",
            "Epoch 94/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.0197 - acc: 0.9930\n",
            "Epoch 95/100\n",
            "426/426 [==============================] - 0s 63us/step - loss: 0.0190 - acc: 0.9930\n",
            "Epoch 96/100\n",
            "426/426 [==============================] - 0s 52us/step - loss: 0.0188 - acc: 0.9930\n",
            "Epoch 97/100\n",
            "426/426 [==============================] - 0s 51us/step - loss: 0.0185 - acc: 0.9930\n",
            "Epoch 98/100\n",
            "426/426 [==============================] - 0s 45us/step - loss: 0.0182 - acc: 0.9953\n",
            "Epoch 99/100\n",
            "426/426 [==============================] - 0s 57us/step - loss: 0.0180 - acc: 0.9953\n",
            "Epoch 100/100\n",
            "426/426 [==============================] - 0s 55us/step - loss: 0.0178 - acc: 0.9953\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 961\n",
            "Trainable params: 961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "143/143 [==============================] - 0s 137us/step\n",
            "[0.14494747142274897, 0.9650349617004395]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}